# AI Model Benchmark Data
Model,"Arena Elo
[Feb 2, 2024]","Arena Elo
[April 18, 2024]",LC AlpacaEval 2.0,AlpacaEval 2.0,AlpacaEval 1.0,"MT-bench
(multi-turn)",WildBench,"Open LLM
(average)","ARC-C
(25-shot)","HellaSwag
(10-shot)","MMLU
(5-shot)","TruthfulQA
(0-shot)","WinoGrande
(5-shot)","GSM-8K
(5-shot)","GPT4All
(average)","AGI Eval 
(en)","HELM 
Lite","BBH, cot
(3-shot)","HumanEval
(pass @1)","LLMonitor
(01-10)","OpenComp.
(en, avg)","MBPP
(pass @1)",Output Length,MixEval-Hard,MixEval,Arena Elo (0527),TriviaQA (Mixed),MMLU (Mixed),DROP (Mixed),HellaSwag (Mixed),CommonsenseQA (Mixed),TriviaQA-Hard (Mixed),MMLU-Hard (Mixed),DROP-Hard (Mixed),InstructEval MMLU,InstructEval BBH,InstructEval DROP,InstructEval CRASS,InstructEval HumanEval,InstructEval Average
gpt-4-turbo-2024-04-09,,1260,55,,,,,,,,,,,,,,,,,,,,,62.6,88.8,1256,91.2,82.8,91,92.6,85.4,73.1,45.5,71,,,,,,
gpt4_1106_preview,,1254,50,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gpt4_0125_preview,1249,,,,,,940.6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
claude-3-opus-20240229,1247,1255,40.5,29.04176413,,,852.6,,,,86.8,,,,,,,,,,,,1388,63.5,88.1,1248,90.4,83.2,91.5,93.3,87.7,71.4,55,75.2,,,,,,
claude-3-sonnet-20240229,1190,1203,34.9,25.55632529,,,835.8,,,,79,,,,,,,,,,,,1420,68.1,89.9,-,92.6,84.2,93.7,94.6,85.4,73.3,58.4,80.4,,,,,,
gpt4_0314,1185,1189,35.3,22.07325893,94.7826087,8.96,,,96.3,95.3,86.4,59,,,,57,,86.7,88.4,93,73.3,,1371,64.7,87.9,1287,88,85.4,87.9,94.3,86.8,70.3,57.1,67.5,86.4,,80.9,,67,
gpt4_0613,1160,1164,30.2,15.75503809,93.78109453,9.18,,,,,,,,,,57,0.962,86.7,88.4,89,73.3,,1140,,,,,,,,,,,,,,,,,
mistral-large-2402,1155,1158,32.7,21.43877598,,,824.2,,,,81.2,,,,,,,,,,,,1362,57.4,86.1,-,88.2,81.9,89.3,80.1,81.6,64.8,42.9,72,,,,,,
Qwen1.5-72B-Chat,1146,1154,36.57175411,26.4982834,,8.61,,,,,77.5,,,,,,,,,,,,1549,48.3,84.1,1147,83.9,80.1,85.1,87.9,86.3,49.9,37.7,56.5,,,,,,
claude,1145,1150,27.28950444,16.98534361,91.55279503,7.9,,,,,77,,,,,49.7,0.724,67.3,56,66,46.3,,1082,,,,,,,,,,,,,,,,,
mistral-medium,1145,1148,28.6,21.85577254,96.83229814,8.61,,,89.9,88,75.3,,88,66.7,,,,,,,,62.3,1500,47.8,81.9,1148,86.8,76.3,83.2,72.4,82.5,59.8,38.5,47.1,,,,,,
claude-2,1126,1131,28.15519614,17.18824036,91.35572139,8.06,,,,,78.5,,,,,,0.679,,71.2,68,,,1069,,,,,,,,,,,,,,,,,
Mistral-Next,1123,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gemini Pro (Dev API),1118,,,,,,,,,,71.8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
claude-2.1,1115,1119,25.25194389,15.73350674,87.08074534,8.18,,,,,,,,,,,0.593,,,,,,1096,,,,,,,,,,,,,,,,,
Mixtral-8x7B-Instruct-v0.1,1114,1114,23.6884826,18.25531763,94.7826087,8.3,765.7,72.62,70.22,87.63,70.6,64.58,81.37,60.73,76.41,45.3,0.728,67,54.9,,56.8,60.7,1465,42.5,76.4,1114,82.5,72,79.5,54.2,77.4,48.5,37.2,47.7,,,,,,
gpt-3.5-turbo-0613,1113,1119,22.35251298,14.09579857,,8.39,,,,,,,,,,,0.507,71,72.6,81,,,1331,,,,,,,,,,,,70,49.6,64.1,90.5,48.1,64.5
gemini-pro,1110,1115,24.38177611,18.17764454,79.6641791,,788,,,,71.8,,,,,,,65.6,63.4,,,72.9,1456,46.4,78.9,1131,81,74.9,82.6,74.7,80.2,58.2,35.5,54.1,,,,,,
GPT-3.5-Turbo-0314,1104,,,,,7.94,,,85.5,70.6,70,,85.2,57.1,,43.2,,,73.2,79,63.5,81.6,,,,,,,,,,,,,,,,,,
claude-instant-1.2,1104,1108,25.61225903,16.12739962,,7.85,,,,,73.4,,,,,,,,52.8,60,,,1112,,,,,,,,,,,,,,,,,
wizardlm-70b,1102,1108,17.57506074,14.38389609,,7.71,,61.25,65.44,84.41,63.7,54.81,80.82,17.97,,,,,,,,,,,,,,,,,,,,,,,,,,
Yi-34B-Chat,1099,1107,27.19054788,29.65994672,94.08468244,,743.9,65.32,65.44,84.16,73.5,55.37,80.11,31.92,72.13,50.8,0.772,71.7,,,63.3,,2123,42.6,80.1,1111,82.7,73.6,86.1,86.9,78.8,41.5,29.9,57.1,,,,,,
tulu-2-dpo-70b,1097,1103,21.23861004,15.98285437,95.0310559,7.89,685.9,73.77,72.1,88.99,69.84,65.78,83.27,62.62,,,,66,,,,,1418,,,,,,,,,,,,,,,,,
dbrx-instruct,,1101,25.4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GPT-3.5-Turbo-0125,1096,,,,,,736.4,,,,,,,,,,,,,,,,,,43,79.7,1102,85.2,74.5,84.8,63,81.6,46.4,35.1,55.4,,,,,
vicuna-33b-v1.3,1089,,17.57457531,12.70594792,88.99253731,7.12,,58.5,,,59.2,,,,,37.3,,52,,,53,,1479,38.7,66.3,1090,79.2,59.2,71.4,30.3,61.8,42.5,39.4,36.6,,,,,,
Starling-LM-7B-alpha,1084,,14.69047108,14.24592352,,8.09,,67.13,63.82,84.9,63.9,46.39,80.58,62.4,72.72,40.1,,,,,,,1895,,,,,,,,,,,,,,,,,
llama-2-70b-chat-hf,1082,,14.68964859,13.88825834,92.66169154,6.86,697.4,62.4,64.59,85.88,63,52.8,80.51,26.69,,45,,60.8,,60,58.6,,1790,38,74.6,1093,80,69.8,79.8,67.3,74.1,42.2,27.7,42.2,62.6,42.6,51,54.4,7.3,43.6
OpenHermes-2.5-Mistral-7B,1079,,16.2485777,10.34041571,,,,61.52,64.93,84.18,63.8,52.24,78.06,26.08,73.12,43,,,48.2,,,,1107,,,,,,,,,,,,,,,,,
NV-Llama2-70B-SteerLM-Chat,1076,,,,,7.54,,,,,68.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mistral-7B-Instruct-v0.2,1073,,17.11125185,14.72277266,92.77708593,7.6,,,,,,,,,,,,,,,,,1676,36.2,70,1072,73.7,67.3,72.8,54.2,66,33.5,29.4,44.3,,,,,,
deepseek-llm-67b-chat,1073,,17.84338409,12.09342226,,,,71.79,67.75,86.82,72.42,55.85,84.21,63.68,,,,,,,,,1151,,,,,,,,,,,,,,,,,
OpenChat-3.5,1071,,,,,7.81,,61.24,63.91,84.79,64.3,46.38,80.58,26.84,72.92,42.7,,,55.5,,,,,,,,,,,,,,,,,,,,,
pplx-70b-online,1068,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SOLAR-10.7B-Instruct-v1.0,1065,,,,,7.58,,74.2,71.08,88.16,66.2,71.43,83.58,64.75,75.11,47.6,,,,,,42.9,,,,,,,,,,,,,,,,,,
dolphin-2.2.1-mistral-7b,1058,,13.12147765,9.039799728,,,,64.93,63.31,83.76,63.2,53.11,78.14,48.07,72.24,39.2,,59.8,,,58,,1130,,,,,,,,,,,,,,,,,
wizardlm-13b-v1.2,1054,,14.46259069,12.02748034,89.16562889,7.2,,54.76,59.04,82.21,52.7,47.27,71.9,13.5,,,,,,,,,1635,,,,,,,,,,,,,,,,,
zephyr-7b-beta,1046,,13.20319849,10.99288576,90.59775841,7.34,662.3,61.95,62.03,84.36,61.4,57.45,77.74,29.04,71,,,,,,,,,,,,,,,,,,,,,,,,,
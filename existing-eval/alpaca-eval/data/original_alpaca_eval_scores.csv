Model,LC_Win_Rate,Win_Rate
GPT-4 Omni (05/13),57.5,51.3
GPT-4 Turbo (04/09),55.0,46.1
Yi-Large Preview,51.9,57.5
GPT-4o Mini (07/18),50.7,44.7
GPT-4 Preview (11/06),50.0,50.0
Claude 3 Opus (02/29),40.5,29.1
Llama 3.1 405B Instruct,39.3,39.1
GPT-4,38.1,23.6
Qwen2 72B Instruct,38.1,29.9
Llama 3.1 70B Instruct,38.1,39.1
Qwen1.5 72B Chat,36.6,26.5
GPT-4 (03/14),35.3,22.1
Claude 3 Sonnet (02/29),34.9,25.6
Llama 3 70B Instruct,34.4,33.2
Mistral Large (24/02),32.7,21.4
Mixtral 8x22B v0.1,30.9,22.2
GPT-4 (06/13),30.2,15.8
Contextual AI (KTO-Mistral-PairRM),29.7,33.2
Mistral Medium,28.6,21.9
Claude 2,28.2,17.2
Claude,27.3,17.0
Yi 34B Chat,27.2,29.7
DBRX Instruct,25.4,18.4
Claude 2.1,25.3,15.7
Gemini Pro,24.4,18.2
Qwen1.5 14B Chat,23.9,18.6
Mixtral 8x7B v0.1,23.7,18.3
Llama 3 8B Instruct,22.9,22.6
GPT 3.5 Turbo (06/13),22.7,14.1
Tulu 2+DPO 70B,21.2,16.0
Llama 3.1 8B Instruct,20.9,21.8
Mistral 7B v0.3,20.6,16.7
GPT 3.5 Turbo (11/06),19.3,9.2
GPT 3.5 Turbo (03/01),18.1,9.6
Vicuna 33B v1.3,17.6,12.7
Mistral 7B v0.2,17.1,14.7
OpenHermes-2.5-Mistral (7B),16.2,10.3
Qwen1.5 7B Chat,14.7,11.8
LLaMA2 Chat 70B,14.7,13.9
Cohere Command,10.9,12.9
Vicuna 13B v1.3,10.8,7.1
Gemma Instruct (7B),10.4,6.9
LLaMA 33B OASST SFT,9.9,4.8
WizardLM 13B,9.8,5.9
Nous Hermes 13B,9.7,5.4
Vicuna 13B,9.2,5.8
Davinci001,9.0,2.8
LLaMA2 Chat 13B,8.4,7.7
Guanaco 65B,8.3,6.9
LLaMA 33B OASST RLHF,8.0,6.3
Phi-2 DPO,7.8,7.8
Vicuna 7B v1.3,7.2,4.6
Alpaca Farm PPO Sim (GPT-4) 7B,7.1,3.5
Alpaca Farm PPO Human 7B,6.4,4.1
Vicuna 7B,6.3,4.2
Alpaca 7B,5.9,2.6
Phi-2 SFT,5.9,4.0
Guanaco 33B,5.7,5.0
Falcon 40B Instruct,5.6,3.3
Gemma Instruct (2B),5.4,3.4
LLaMA2 Chat 7B,5.4,5.0
Pythia 12B SFT,4.2,2.6
Falcon 7B Instruct,4.0,2.1
Pythia 12B OASST SFT,3.3,1.8
Guanaco 13B,3.0,3.5
Guanaco 7B,2.9,2.9
Qwen1.5 1.8B Chat,2.6,3.7